{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad95891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from farkle.simulation import (  # _play_game → single game:contentReference[oaicite:1]{index=1}\n",
    "    _play_game,\n",
    "    generate_strategy_grid,\n",
    ")\n",
    "from farkle.stats import games_for_power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fbb8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Powered sample ⇒ each strategy appears 7,333 times.\n",
      "Total games scheduled: 11,967,456\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# run_tournament.py  ── wake-up-and-done edition\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ─── 1. Build the master grid ────────────────────────────────────────────────\n",
    "strategies, meta = generate_strategy_grid()        # 8 160 objects\n",
    "meta[\"str_repr\"] = [str(s) for s in strategies]    # convenient lookup\n",
    "\n",
    "# ─── 2. Powered sample size *per strategy* ───────────────────────────────────\n",
    "n_games_per_player = games_for_power(\n",
    "    n_strategies = len(strategies),\n",
    "    delta        = 0.03,    # 3-percentage-point lift\n",
    "    alpha        = 0.05,\n",
    "    power        = 0.80,\n",
    "    method       = \"bh\",\n",
    "    pairwise     = True,\n",
    ")\n",
    "# Example: n_games_per_player ≈ 7 300  →  8 160×7 300/5 ≈ 11.9 M games\n",
    "print(f\"Powered sample ⇒ each strategy appears {n_games_per_player:,} times.\")\n",
    "\n",
    "# ─── 3. Balanced table scheduler (lazy generator, zero RAM blow-up) ──────────\n",
    "def chunker(it, n):\n",
    "    while (batch := list(islice(it, n))):\n",
    "        yield tuple(batch)          # tuple → picklable & hashable\n",
    "\n",
    "def make_tables(strats, repeats, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for _ in range(repeats):\n",
    "        perm = rng.permutation(len(strats))        # shuffle once per round\n",
    "        yield from chunker(perm, 5)\n",
    "\n",
    "tables_iter = make_tables(strategies, n_games_per_player)\n",
    "total_games = len(strategies) * n_games_per_player // 5\n",
    "print(f\"Total games scheduled: {total_games:,}\")\n",
    "\n",
    "# ─── 4. Worker function (index-based to save bandwidth) ──────────────────────\n",
    "def _one(task):\n",
    "    seed, idxs = task\n",
    "    table = [strategies[i] for i in idxs]          # rebuild objects locally\n",
    "    row   = _play_game(seed, table, 10_000)\n",
    "    winner = row[\"winner\"]\n",
    "    return str(row[f\"{winner}_strategy\"])          # string repr\n",
    "\n",
    "# Master seed stream (lazy, same pace as tables_iter)\n",
    "def task_stream():\n",
    "    rng = np.random.default_rng(999)               # independent RNG\n",
    "    for idxs in tables_iter:\n",
    "        yield (rng.integers(0, 2**32 - 1), idxs)\n",
    "\n",
    "# ─── 5. Run the tournament with 12 processes ─────────────────────────────────\n",
    "t0 = time.perf_counter()\n",
    "win_counter = Counter()\n",
    "\n",
    "with mp.Pool(processes=12, maxtasksperchild=500) as pool:\n",
    "    first = True\n",
    "    for win in pool.imap_unordered(_one, task_stream(), chunksize=100):\n",
    "        if first:\n",
    "            print(\"▶▶▶ pool.imap_unordered is producing tasks\")\n",
    "            first = False\n",
    "        win_counter[win] += 1\n",
    "elapsed = time.perf_counter() - t0\n",
    "print(f\"Finished {total_games:,} games in {elapsed/3600:,.2f} hours.\")\n",
    "\n",
    "# ─── 6. Tally → CSV ──────────────────────────────────────────────────────────\n",
    "summary = (\n",
    "    meta[[\"strategy_idx\", \"str_repr\"]]\n",
    "      .assign(wincount=lambda df: df[\"str_repr\"]\n",
    "                                 .map(win_counter)\n",
    "                                 .fillna(0)\n",
    "                                 .astype(\"int32\"))\n",
    "      .sort_values(\"strategy_idx\")[[\"strategy_idx\", \"wincount\"]]\n",
    ")\n",
    "summary.to_csv(\"wincounts.csv\", index=False)\n",
    "print(\"Wrote wincounts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ff4e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10223\n",
      "16683936\n"
     ]
    }
   ],
   "source": [
    "n_games_per_player = games_for_power(\n",
    "    n_strategies = 8160,\n",
    "    delta        = 0.03,    # Strat win rate difference\n",
    "    alpha        = 0.025,    # p-value analogue - overall false positive tolerance\n",
    "    power        = 0.90,\n",
    "    method       = \"bh\",\n",
    "    pairwise     = True,\n",
    ")\n",
    "print(n_games_per_player)\n",
    "print(n_games_per_player*8160//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469b81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,223 appearances → 16,683,936 total games.\n"
     ]
    }
   ],
   "source": [
    "# run_tournament_v2.py  ── progress-aware, chunked, all threads\n",
    "# -------------------------------------------------------------\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "from farkle.simulation import generate_strategy_grid\n",
    "from farkle.stats import games_for_power\n",
    "\n",
    "# ─── 1. Master grid ───────────────────────────────────────────────────────────\n",
    "strategies, meta = generate_strategy_grid()\n",
    "meta[\"str_repr\"] = [str(s) for s in strategies]\n",
    "\n",
    "# ─── 2. Powered sample size ──────────────────────────────────────────────────\n",
    "n_games_per_player = games_for_power(\n",
    "    n_strategies=len(strategies), delta=0.03, alpha=0.025,\n",
    "    power=0.90, method=\"bh\", pairwise=True,\n",
    ")\n",
    "total_games = len(strategies) * n_games_per_player // 5\n",
    "print(f\"{n_games_per_player:,} appearances → {total_games:,} total games.\")\n",
    "\n",
    "# ─── 3. Table generator ──────────────────────────────────────────────────────\n",
    "def chunker(it, n):\n",
    "    while (batch := list(islice(it, n))):\n",
    "        yield tuple(batch)\n",
    "\n",
    "def make_tables(strats, repeats, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for _ in range(repeats):\n",
    "        yield from chunker(rng.permutation(len(strats)), 5)\n",
    "\n",
    "tables_iter = make_tables(strategies, n_games_per_player)\n",
    "# quick sanity check:\n",
    "peek = list(islice(tables_iter, 2))\n",
    "print(\"First two tables (just indices):\", peek)\n",
    "# Then rebuild it, since islice consumed it:\n",
    "tables_iter = make_tables(strategies, n_games_per_player)\n",
    "\n",
    "# ─── 4. Worker ----------------------------------------------------------------\n",
    "def _one(task):\n",
    "    seed, idxs = task\n",
    "    table = [strategies[i] for i in idxs]\n",
    "    row   = _play_game(seed, table, 10_000)\n",
    "    return str(row[f\"{row['winner']}_strategy\"])\n",
    "\n",
    "def task_stream():\n",
    "    rng = np.random.default_rng(999)\n",
    "    for idxs in tables_iter:\n",
    "        yield (rng.integers(0, 2**32 - 1), idxs)\n",
    "\n",
    "# ─── 5. Tournament loop with progress / checkpoints ---------------------------\n",
    "CHUNKSIZE         = 10_000\n",
    "PROCESSES         = 16          # all logical threads\n",
    "MAXTASKS          = 50\n",
    "REPORT_EVERY      = 100_000   # games\n",
    "CHECKPOINT_FILE   = \"win_counter.chk\"\n",
    "\n",
    "def save_checkpoint(counter, done):\n",
    "    with open(CHECKPOINT_FILE, \"wb\") as f:\n",
    "        pickle.dump({\"done\": done, \"counter\": dict(counter)}, f)\n",
    "\n",
    "def main():\n",
    "    print(\"Entered main() at\", time.asctime())\n",
    "    start = time.perf_counter()\n",
    "    win_counter = Counter()\n",
    "    done_games  = 0\n",
    "\n",
    "    with mp.Pool(processes=PROCESSES,\n",
    "                 maxtasksperchild=MAXTASKS) as pool:\n",
    "\n",
    "        first = True\n",
    "        for win in pool.imap_unordered(_one, task_stream(), chunksize=CHUNKSIZE):\n",
    "            if first:\n",
    "                print(\"pool.imap_unordered is producing tasks\")\n",
    "                first = False\n",
    "            win_counter[win] += 1\n",
    "            done_games += 1\n",
    "\n",
    "            if done_games % REPORT_EVERY == 0:\n",
    "                pct = 100 * done_games / total_games\n",
    "                hrs = (time.perf_counter() - start) / 3600\n",
    "                print(f\"{done_games:,}/{total_games:,}  \"\n",
    "                      f\"({pct:5.2f} %)  {hrs:5.2f} h\")\n",
    "                save_checkpoint(win_counter, done_games)\n",
    "\n",
    "    # final save\n",
    "    save_checkpoint(win_counter, done_games)\n",
    "\n",
    "    elapsed = (time.perf_counter() - start) / 3600\n",
    "    print(f\"Finished in {elapsed:,.2f} hours\")\n",
    "\n",
    "    summary = (\n",
    "        meta[[\"strategy_idx\", \"str_repr\"]]\n",
    "          .assign(wincount=lambda df:\n",
    "                  df[\"str_repr\"].map(win_counter).fillna(0).astype(\"int32\"))\n",
    "          .sort_values(\"strategy_idx\")[[\"strategy_idx\", \"wincount\"]]\n",
    "    )\n",
    "    summary.to_csv(\"wincounts.csv\", index=False)\n",
    "    print(\"→ wincounts.csv written\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f003cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: n_games_per_player = 10223\n",
      "DEBUG: changed n_games_per_player = 2\n",
      "DEBUG: total_games = 3264\n",
      "▶ Scheduling 3,264 total games.\n",
      "\n",
      "DEBUG: First two tables of indices: [(np.int64(5231), np.int64(3151), np.int64(6782), np.int64(5491), np.int64(4091)), (np.int64(5231), np.int64(3151), np.int64(6782), np.int64(5491), np.int64(4091))]\n",
      "DEBUG → Peeking at task_stream instead of tables_iter alone:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'task_stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDEBUG → Peeking at task_stream instead of tables_iter alone:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m _orig_tables = make_tables(strategies, n_games_per_player)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m tsk = \u001b[43mtask_stream\u001b[49m()       \u001b[38;5;66;03m# uses tables_iter internally, but let's bypass it\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Instead, force task_stream to use a fresh make_tables:\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtest_task_stream\u001b[39m():\n",
      "\u001b[31mNameError\u001b[39m: name 'task_stream' is not defined"
     ]
    }
   ],
   "source": [
    "# run_tournament_v2.py  ── progress-aware, chunked, all threads\n",
    "# -------------------------------------------------------------\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "from farkle.simulation import generate_strategy_grid\n",
    "from farkle.stats import games_for_power\n",
    "\n",
    "# ─── 1. Master grid ───────────────────────────────────────────────────────────\n",
    "strategies, meta = generate_strategy_grid()\n",
    "meta[\"str_repr\"] = [str(s) for s in strategies]\n",
    "# ─── 2. Powered sample size ──────────────────────────────────────────────────\n",
    "n_games_per_player = games_for_power(\n",
    "    n_strategies=len(strategies), delta=0.03, alpha=0.025,\n",
    "    power=0.90, method=\"bh\", pairwise=True,\n",
    ")\n",
    "print(f\"DEBUG: n_games_per_player = {n_games_per_player}\")\n",
    "\n",
    "################ DEBUGGING IO ################\n",
    "n_games_per_player = 2\n",
    "print(f\"DEBUG: changed n_games_per_player = {n_games_per_player}\")\n",
    "\n",
    "total_games = len(strategies) * n_games_per_player // 5\n",
    "print(f\"DEBUG: total_games = {total_games}\")\n",
    "print(f\"▶ Scheduling {total_games:,} total games.\\n\")\n",
    "\n",
    "# ─── 3. Table generator ──────────────────────────────────────────────────────\n",
    "def chunker(it, n):\n",
    "    while (batch := list(islice(it, n))):\n",
    "        yield tuple(batch)\n",
    "\n",
    "def make_tables(strats, repeats, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for _ in range(repeats):\n",
    "        yield from chunker(rng.permutation(len(strats)), 5)\n",
    "\n",
    "# Sanity-check peek:\n",
    "tables_iter = make_tables(strategies, n_games_per_player)\n",
    "first_two = list(islice(tables_iter, 2))\n",
    "print(\"DEBUG: First two tables of indices:\", first_two)\n",
    "print(\"DEBUG → Peeking at task_stream instead of tables_iter alone:\")\n",
    "_orig_tables = make_tables(strategies, n_games_per_player)\n",
    "tsk = task_stream()       # uses tables_iter internally, but let's bypass it\n",
    "# Instead, force task_stream to use a fresh make_tables:\n",
    "def test_task_stream():\n",
    "    rng = np.random.default_rng(999)\n",
    "    for idxs in make_tables(strategies, n_games_per_player):\n",
    "        yield (rng.integers(0, 2**32 - 1), idxs)\n",
    "\n",
    "first_task = next(test_task_stream(), None)\n",
    "print(\"DEBUG → first task from test_task_stream():\", first_task)\n",
    "second_task = next(test_task_stream(), None)\n",
    "print(\"DEBUG → second task from test_task_stream():\", second_task)\n",
    "# Rebuild it, since peek consumed 2 games:\n",
    "tables_iter = make_tables(strategies, n_games_per_player)\n",
    "\n",
    "# ─── 4. Worker ----------------------------------------------------------------\n",
    "def _one(task):\n",
    "    seed, idxs = task\n",
    "    table = [strategies[i] for i in idxs]\n",
    "    row   = _play_game(seed, table, 10_000)\n",
    "    return str(row[f\"{row['winner']}_strategy\"])\n",
    "\n",
    "def task_stream():\n",
    "    rng = np.random.default_rng(999)\n",
    "    for idxs in tables_iter:\n",
    "        yield (rng.integers(0, 2**32 - 1), idxs)\n",
    "\n",
    "# ─── 5. Tournament loop with progress / checkpoints ---------------------------\n",
    "CHUNKSIZE         = 10_000\n",
    "PROCESSES         = 16\n",
    "MAXTASKS          = 50\n",
    "REPORT_EVERY      = 100_000\n",
    "CHECKPOINT_FILE   = \"win_counter.chk\"\n",
    "\n",
    "def save_checkpoint(counter, done):\n",
    "    with open(CHECKPOINT_FILE, \"wb\") as f:\n",
    "        pickle.dump({\"done\": done, \"counter\": dict(counter)}, f)\n",
    "\n",
    "def main():\n",
    "    print(\"▶▶▶ Entered main() at\", time.asctime())\n",
    "    start = time.perf_counter()\n",
    "    win_counter = Counter()\n",
    "    done_games  = 0\n",
    "    seen_first = False\n",
    "\n",
    "    with mp.Pool(processes=PROCESSES,\n",
    "                 maxtasksperchild=MAXTASKS) as pool:\n",
    "\n",
    "        for win in pool.imap_unordered(_one, task_stream(), chunksize=CHUNKSIZE):\n",
    "            if not seen_first:\n",
    "                print(\"▶ pool.imap_unordered has started returning wins.\")\n",
    "                seen_first = True\n",
    "\n",
    "            win_counter[win] += 1\n",
    "            done_games += 1\n",
    "\n",
    "            if done_games % REPORT_EVERY == 0:\n",
    "                pct = 100 * done_games / total_games\n",
    "                hrs = (time.perf_counter() - start) / 3600\n",
    "                print(f\"{done_games:,}/{total_games:,}  \"\n",
    "                      f\"({pct:5.2f} %)  {hrs:5.2f} h\")\n",
    "                save_checkpoint(win_counter, done_games)\n",
    "\n",
    "  # final save\n",
    "    save_checkpoint(win_counter, done_games)\n",
    "\n",
    "    elapsed = (time.perf_counter() - start) / 3600\n",
    "    print(f\"Finished in {elapsed:,.2f} hours\")\n",
    "\n",
    "    summary = (\n",
    "        meta[[\"strategy_idx\", \"str_repr\"]]\n",
    "          .assign(wincount=lambda df:\n",
    "                  df[\"str_repr\"].map(win_counter).fillna(0).astype(\"int32\"))\n",
    "          .sort_values(\"strategy_idx\")[[\"strategy_idx\", \"wincount\"]]\n",
    "    )\n",
    "    summary.to_csv(\"wincounts.csv\", index=False)\n",
    "    print(\"→ wincounts.csv written\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f071acad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG → n_games_per_player = 10223\n",
      "DEBUG → total_games        = 16683936\n",
      "▶ Scheduling 16,683,936 total games.\n",
      "\n",
      "DEBUG → First two tables of indices: [(np.int64(5231), np.int64(3151), np.int64(6782), np.int64(5491), np.int64(4091)), (np.int64(5231), np.int64(3151), np.int64(6782), np.int64(5491), np.int64(4091))]\n",
      "\n",
      "DEBUG → Peeking at task_stream directly:\n",
      "DEBUG → first task from test_task_stream(): (np.int64(3495654652), (np.int64(5231), np.int64(3151), np.int64(6782), np.int64(5491), np.int64(4091)))\n",
      "DEBUG → second task from test_task_stream(): (np.int64(3495654652), (np.int64(5231), np.int64(3151), np.int64(6782), np.int64(5491), np.int64(4091)))\n",
      "\n",
      "DEBUG → Calling _one() on that single task …\n",
      "DEBUG → _one(dbg_task) returned: Strat(450,2)[--][F-PS][OR][H-]\n",
      "▶▶▶ Entered main() at Fri Jun  6 14:41:28 2025\n",
      "Pool is open\n"
     ]
    }
   ],
   "source": [
    "# run_tournament_v2_debug_fixed.py  ── fully ordered & rebuilt generator\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "from farkle.simulation import generate_strategy_grid\n",
    "from farkle.stats import games_for_power\n",
    "\n",
    "# ─── 1. Master grid ───────────────────────────────────────────────────────────\n",
    "strategies, meta = generate_strategy_grid()   # length = 8_160\n",
    "meta[\"str_repr\"] = [str(s) for s in strategies]\n",
    "\n",
    "# ─── 2. Powered sample size ──────────────────────────────────────────────────\n",
    "n_games_per_player = games_for_power(\n",
    "    n_strategies=len(strategies),\n",
    "    delta=0.03, alpha=0.025,\n",
    "    power=0.90, method=\"bh\", pairwise=True,\n",
    ")\n",
    "total_games = len(strategies) * n_games_per_player // 5\n",
    "\n",
    "print(f\"DEBUG → n_games_per_player = {n_games_per_player}\")\n",
    "print(f\"DEBUG → total_games        = {total_games}\")\n",
    "print(f\"▶ Scheduling {total_games:,} total games.\\n\")\n",
    "\n",
    "# ─── 3. Table generator ──────────────────────────────────────────────────────\n",
    "def chunker(it, n):\n",
    "    while (batch := list(islice(it, n))):\n",
    "        yield tuple(batch)\n",
    "\n",
    "def make_tables(strats, repeats, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for _ in range(repeats):\n",
    "        yield from chunker(rng.permutation(len(strats)), 5)\n",
    "\n",
    "# ─── 3a. Peek at the first two tables (and then exhaust those two) ───────────\n",
    "tables_iter = make_tables(strategies, n_games_per_player)\n",
    "first_two = list(islice(tables_iter, 2))\n",
    "print(\"DEBUG → First two tables of indices:\", first_two)\n",
    "\n",
    "# ─── 3b. NOW rebuild tables_iter for real work ──────────────────────────────\n",
    "tables_iter = make_tables(strategies, n_games_per_player)\n",
    "\n",
    "# ─── 4. Worker function ───────────────────────────────────────────────────────\n",
    "def _one(task):\n",
    "    seed, idxs = task\n",
    "    table = [strategies[i] for i in idxs]\n",
    "    row   = _play_game(seed, table, 10_000)\n",
    "    return str(row[f\"{row['winner']}_strategy\"])\n",
    "\n",
    "# ─── 5. Define task_stream (uses the fresh tables_iter) ───────────────────────\n",
    "def task_stream():\n",
    "    rng = np.random.default_rng(999)\n",
    "    for idxs in tables_iter:\n",
    "        yield (rng.integers(0, 2**32 - 1), idxs)\n",
    "\n",
    "# Sanity check: peek at task_stream itself (fresh copy) ────────────────────────\n",
    "print(\"\\nDEBUG → Peeking at task_stream directly:\")\n",
    "def test_task_stream():\n",
    "    rng = np.random.default_rng(999)\n",
    "    for idxs in make_tables(strategies, n_games_per_player):\n",
    "        yield (rng.integers(0, 2**32 - 1), idxs)\n",
    "\n",
    "tsk1 = next(test_task_stream(), None)\n",
    "print(\"DEBUG → first task from test_task_stream():\", tsk1)\n",
    "tsk2 = next(test_task_stream(), None)\n",
    "print(\"DEBUG → second task from test_task_stream():\", tsk2)\n",
    "\n",
    "# ─── 6. Quick dry‐run of _one(...) on a single task ────────────────────────────\n",
    "debug_tables = make_tables(strategies, n_games_per_player)\n",
    "dbg_idxs = next(debug_tables, None)\n",
    "dbg_seed = np.random.default_rng(999).integers(0, 2**32 - 1)\n",
    "dbg_task = (dbg_seed, dbg_idxs)\n",
    "\n",
    "print(\"\\nDEBUG → Calling _one() on that single task …\")\n",
    "try:\n",
    "    dbg_result = _one(dbg_task)\n",
    "    print(\"DEBUG → _one(dbg_task) returned:\", dbg_result)\n",
    "except Exception as e:\n",
    "    print(\"DEBUG → _one(dbg_task) raised an exception:\", e)\n",
    "    import traceback; traceback.print_exc()\n",
    "\n",
    "# ─── 7. Tournament loop with fresh generator & progress prints ───────────────\n",
    "CHUNKSIZE         = 10_000\n",
    "PROCESSES         = 16\n",
    "MAXTASKS          = 50\n",
    "REPORT_EVERY      = 100_000\n",
    "CHECKPOINT_FILE   = \"win_counter.chk\"\n",
    "\n",
    "def save_checkpoint(counter, done):\n",
    "    with open(CHECKPOINT_FILE, \"wb\") as f:\n",
    "        pickle.dump({\"done\": done, \"counter\": dict(counter)}, f)\n",
    "\n",
    "def main():\n",
    "    print(\"▶▶▶ Entered main() at\", time.asctime())\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    win_counter = Counter()\n",
    "    done_games  = 0\n",
    "    seen_first  = False\n",
    "\n",
    "    with mp.Pool(processes=PROCESSES,\n",
    "                 maxtasksperchild=MAXTASKS) as pool:\n",
    "\n",
    "        print(\"Pool is open\")\n",
    "        for win in pool.imap_unordered(_one, task_stream(), chunksize=CHUNKSIZE):\n",
    "            if not seen_first:\n",
    "                print(\"▶ pool.imap_unordered has started returning wins.\")\n",
    "                seen_first = True\n",
    "\n",
    "            win_counter[win] += 1\n",
    "            done_games += 1\n",
    "\n",
    "            if done_games % REPORT_EVERY == 0:\n",
    "                pct = 100 * done_games / total_games\n",
    "                hrs = (time.perf_counter() - start) / 3600\n",
    "                print(f\"{done_games:,}/{total_games:,}  ({pct:5.2f} %)  {hrs:5.2f} h\")\n",
    "                save_checkpoint(win_counter, done_games)\n",
    "\n",
    "    # final save\n",
    "    save_checkpoint(win_counter, done_games)\n",
    "\n",
    "    elapsed = (time.perf_counter() - start) / 3600\n",
    "    print(f\"\\nFinished in {elapsed:,.2f} hours\")\n",
    "\n",
    "    summary = (\n",
    "        meta[[\"strategy_idx\", \"str_repr\"]]\n",
    "          .assign(wincount=lambda df:\n",
    "                  df[\"str_repr\"].map(win_counter).fillna(0).astype(\"int32\"))\n",
    "          .sort_values(\"strategy_idx\")[[\"strategy_idx\", \"wincount\"]]\n",
    "    )\n",
    "    summary.to_csv(\"wincounts.csv\", index=False)\n",
    "    print(\"→ wincounts.csv written\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babdd600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Powered sample ⇒ each strategy appears 10,223 times.\n",
      "Total games scheduled: 16,683,936\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "run_tournament_v2.py – multiprocess round-robin Farkle tournament\n",
    "\"\"\"\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from farkle.simulation import generate_strategy_grid\n",
    "from farkle.stats import games_for_power\n",
    "\n",
    "# ─── 0.  Globals filled by pool.initializer ─────────────────────────────────\n",
    "strategies: list | None = None       # type: ignore\n",
    "meta:       pd.DataFrame | None = None  # type: ignore\n",
    "\n",
    "def _init_worker(shared_strats, shared_meta):\n",
    "    global strategies, meta\n",
    "    strategies = shared_strats\n",
    "    meta       = shared_meta\n",
    "\n",
    "# ─── 1.  Combinatorial helpers ─────────────────────────────────────────────\n",
    "def chunker(it, n):\n",
    "    while (batch := list(islice(it, n))):\n",
    "        yield tuple(batch)\n",
    "\n",
    "def make_tables(strats, repeats, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for _ in range(repeats):\n",
    "        yield from chunker(rng.permutation(len(strats)), 5)\n",
    "\n",
    "# ─── 2.  Worker – purely functional, pickle-safe ───────────────────────────\n",
    "def _one(task):\n",
    "    seed, idxs = task\n",
    "    table = [strategies[i] for i in idxs]        # strategies seen via global\n",
    "    row   = _play_game(seed, table, 10_000)\n",
    "    return row[f\"{row['winner']}_strategy\"]      # already a str\n",
    "\n",
    "# ─── 3.  Lazy task generator ───────────────────────────────────────────────\n",
    "def task_stream(repeats):\n",
    "    rng = np.random.default_rng(999)\n",
    "    for idxs in make_tables(strategies, repeats):\n",
    "        yield int(rng.integers(0, 2**32 - 2)), tuple(int(i) for i in idxs)\n",
    "\n",
    "# ─── 4.  Main driver ───────────────────────────────────────────────────────\n",
    "def main():\n",
    "    CHUNKSIZE, PROCESSES, MAXTASKS = 10_000, 16, 50\n",
    "    REPORT_EVERY, CHECKPOINT = 100_000, \"win_counter.chk\"\n",
    "\n",
    "    n_games_per_player = games_for_power(\n",
    "        n_strategies=len(strategies),\n",
    "        delta=0.03, alpha=0.025, power=0.90, method=\"bh\", pairwise=True,\n",
    "    )\n",
    "    total_games = len(strategies) * n_games_per_player // 5\n",
    "\n",
    "    print(f\"Powered sample ⇒ each strategy appears {n_games_per_player:,} times.\")\n",
    "    print(f\"Total games scheduled: {total_games:,}\")\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    win_counter, done = Counter(), 0\n",
    "\n",
    "    def save():\n",
    "        with open(CHECKPOINT, \"wb\") as f:\n",
    "            pickle.dump({\"done\": done, \"counter\": dict(win_counter)}, f)\n",
    "\n",
    "    with mp.Pool(PROCESSES, maxtasksperchild=MAXTASKS,\n",
    "                 initializer=_init_worker,\n",
    "                 initargs=(strategies, meta)) as pool:\n",
    "        for win in pool.imap_unordered(_one,\n",
    "                                       task_stream(n_games_per_player),\n",
    "                                       chunksize=CHUNKSIZE):\n",
    "            win_counter[win] += 1\n",
    "            done += 1\n",
    "            if done % REPORT_EVERY == 0:\n",
    "                elapsed = (time.perf_counter() - start) / 3600\n",
    "                pct = 100 * done / total_games\n",
    "                print(f\"{done:,}/{total_games:,}  ({pct:4.1f} %)  {elapsed:5.2f} h\")\n",
    "                save()\n",
    "    save()\n",
    "\n",
    "    hrs = (time.perf_counter() - start) / 3600\n",
    "    print(f\"\\nFinished in {hrs:,.2f} hours\")\n",
    "\n",
    "    (meta[[\"strategy_idx\", \"str_repr\"]]\n",
    "        .assign(wincount=lambda df: df[\"str_repr\"].map(win_counter).fillna(0).astype(\"int32\"))\n",
    "        .sort_values(\"strategy_idx\")[[\"strategy_idx\", \"wincount\"]]\n",
    "        .to_csv(\"wincounts.csv\", index=False))\n",
    "    print(\"→ wincounts.csv written\")\n",
    "\n",
    "# ─── 5.  Safe entry-point ──────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    mp.freeze_support()                     # Windows friendliness\n",
    "    strategies, meta = generate_strategy_grid()\n",
    "    meta[\"str_repr\"] = [str(s) for s in strategies]\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce0626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:47:17|MainProcess|INFO|n_games_per_player = 10223, total tasks = 16683936\n",
      "14:47:17|MainProcess|INFO|Pool started with 16 workers.\n"
     ]
    }
   ],
   "source": [
    "# run_tournament_v2_debug_fixed.py\n",
    "\"\"\"\n",
    "Run the full Farkle strategy tournament with multiprocessing,\n",
    "queue-based logging, and resumable checkpoints.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import logging.handlers\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from farkle.simulation import generate_strategy_grid\n",
    "from farkle.stats import games_for_power\n",
    "\n",
    "\n",
    "class FirstNFilter(logging.Filter):\n",
    "    \"\"\"\n",
    "    Let every unique call-site (file, lineno) speak `n` times, then silence it.\n",
    "    Works no matter how tight the surrounding loop is.\n",
    "    \"\"\"\n",
    "    def __init__(self, n: int = 10):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.seen: Counter[Tuple[str, int]] = Counter()\n",
    "\n",
    "    def filter(self, record: logging.LogRecord) -> bool:\n",
    "        key = (record.pathname, record.lineno)\n",
    "        self.seen[key] += 1\n",
    "        return self.seen[key] <= self.n\n",
    "    \n",
    "    \n",
    "DEBUG_FIRST_N = 10    # change once; used by the filter above\n",
    "\n",
    "root = logging.getLogger()             # grab root so *all* libraries inherit it\n",
    "root.setLevel(logging.DEBUG)           # we really want to see DEBUG\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)           # print to notebook cell\n",
    "handler.setFormatter(logging.Formatter(\n",
    "        \"%(asctime)s %(levelname)-5s %(filename)s:%(lineno)d | %(message)s\",\n",
    "        datefmt=\"%H:%M:%S\"))\n",
    "handler.addFilter(FirstNFilter(DEBUG_FIRST_N))        # <── the magic!\n",
    "\n",
    "root.handlers[:] = [handler]            # replace any default Jupyter handlers\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 0.--- Globals & tuning knobs\n",
    "CHUNKSIZE       = 10_000          # tasks sent to each worker at a time\n",
    "PROCESSES       = 16\n",
    "MAXTASKS        = 50              # fork a fresh worker after this many tasks\n",
    "REPORT_EVERY    = 100_000         # progress print interval\n",
    "CHECKPOINT_FILE = Path(\"win_counter.chk\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1.--- Strategy grid and powered sample size\n",
    "strategies, meta = generate_strategy_grid()   # 8 160 rows\n",
    "meta[\"str_repr\"] = [str(s) for s in strategies]\n",
    "\n",
    "n_games_per_player = games_for_power(\n",
    "    n_strategies=len(strategies),\n",
    "    delta=0.03, alpha=0.025, power=0.90,\n",
    "    method=\"bh\", pairwise=True,\n",
    ")\n",
    "total_tasks = len(strategies) * n_games_per_player // 5  # == total games\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format=\"%(asctime)s|%(processName)s|%(levelname)s|%(message)s\",\n",
    "    datefmt=\"%H:%M:%S\")\n",
    "\n",
    "log = logging.getLogger(\"tournament\")\n",
    "log.info(\"n_games_per_player = %s, total tasks = %s\", n_games_per_player, total_tasks)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.--- Utility: chunk iterable into batches of n\n",
    "def chunker(it, n):\n",
    "    while (batch := list(islice(it, n))):\n",
    "        yield tuple(batch)\n",
    "\n",
    "# 3.--- Deterministic table generator  (same order every run for reproducibility)\n",
    "def make_tables(strats, repeats, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for rep in range(repeats):\n",
    "        perm = rng.permutation(len(strats))\n",
    "        yield from chunker(perm, 5)\n",
    "        if rep < 2:                      # quick preview\n",
    "            log.debug(\"rep=%d first table indices=%s\", rep, perm[:5])\n",
    "\n",
    "# 4.--- Worker\n",
    "def _one(task):\n",
    "    seed, idxs = task\n",
    "    table = [strategies[i] for i in idxs]\n",
    "    row   = _play_game(seed, table, 10_000)\n",
    "    win   = str(row[f\"{row['winner']}_strategy\"])\n",
    "    return win\n",
    "\n",
    "# 5.--- Build the (potentially resumable) task stream\n",
    "def task_stream(already_done: int):\n",
    "    \"\"\"\n",
    "    Generator of (seed, indices) tuples.\n",
    "    If *already_done* > 0, the first that many tasks are discarded so that\n",
    "    the stream yields only unfinished work when resuming from a checkpoint.\n",
    "    \"\"\"\n",
    "    rng         = np.random.default_rng(999)\n",
    "    tables_iter = make_tables(strategies, n_games_per_player)\n",
    "\n",
    "    # fast-forward to resume point\n",
    "    if already_done:\n",
    "        skipped = 0\n",
    "        for _ in range(already_done):\n",
    "            next(tables_iter)\n",
    "            skipped += 1\n",
    "        log.info(\"Skipped %s completed tasks from previous run.\", skipped)\n",
    "\n",
    "    for idxs in tables_iter:\n",
    "        yield (rng.integers(0, 2**32 - 1), idxs)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 6.--- Checkpoint helpers\n",
    "def save_checkpoint(counter: Counter, done: int):\n",
    "    with CHECKPOINT_FILE.open(\"wb\") as f:\n",
    "        pickle.dump({\"done\": done, \"counter\": dict(counter)}, f)\n",
    "    log.info(\"Checkpoint saved at %s tasks.\", done)\n",
    "\n",
    "def load_checkpoint() -> tuple[int, Counter]:\n",
    "    if not CHECKPOINT_FILE.exists():\n",
    "        return 0, Counter()\n",
    "    with CHECKPOINT_FILE.open(\"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    log.info(\"Checkpoint loaded: %s tasks finished previously.\", data[\"done\"])\n",
    "    return data[\"done\"], Counter(data[\"counter\"])\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 7.--- Multiprocessing-friendly logging (single queue sink)\n",
    "def _configure_worker_logging(queue):\n",
    "    qh = logging.handlers.QueueHandler(queue)\n",
    "    root = logging.getLogger()\n",
    "    root.handlers.clear()\n",
    "    root.setLevel(logging.DEBUG)\n",
    "    root.addHandler(qh)\n",
    "\n",
    "def _listener_process(queue):\n",
    "    h = logging.StreamHandler(sys.stdout)\n",
    "    fmt = logging.Formatter(\"%(asctime)s|%(processName)s|%(levelname)s|%(message)s\",\n",
    "                            \"%H:%M:%S\")\n",
    "    h.setFormatter(fmt)\n",
    "    root = logging.getLogger()\n",
    "    root.addHandler(h)\n",
    "    root.setLevel(logging.DEBUG)\n",
    "    while True:\n",
    "        record = queue.get()\n",
    "        if record is None:\n",
    "            break\n",
    "        root.handle(record)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    already_done, win_counter = load_checkpoint()\n",
    "    if already_done >= total_tasks:\n",
    "        log.warning(\"All %s tasks are already complete. Nothing to do!\", total_tasks)\n",
    "        return\n",
    "\n",
    "    log_queue = mp.Queue()\n",
    "    listener  = mp.Process(target=_listener_process, args=(log_queue,), daemon=True)\n",
    "    listener.start()\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    done = already_done\n",
    "\n",
    "    with mp.Pool(\n",
    "        processes=PROCESSES,\n",
    "        maxtasksperchild=MAXTASKS,\n",
    "        initializer=_configure_worker_logging,\n",
    "        initargs=(log_queue,),\n",
    "    ) as pool:\n",
    "\n",
    "        log.info(\"Pool started with %d workers.\", PROCESSES)\n",
    "        stream = task_stream(already_done)\n",
    "        for win in pool.imap_unordered(_one, stream, chunksize=CHUNKSIZE):\n",
    "            win_counter[win] += 1\n",
    "            done += 1\n",
    "\n",
    "            if done % REPORT_EVERY == 0 or done == total_tasks:\n",
    "                pct = 100 * done / total_tasks\n",
    "                hrs = (time.perf_counter() - start_time) / 3600\n",
    "                log.info(\"[%10d / %10d]  %6.2f %%  %6.2f h elapsed\",\n",
    "                         done, total_tasks, pct, hrs)\n",
    "                save_checkpoint(win_counter, done)\n",
    "\n",
    "    # tell listener to finish\n",
    "    log_queue.put(None)\n",
    "    listener.join()\n",
    "\n",
    "    # final dump + CSV\n",
    "    save_checkpoint(win_counter, done)\n",
    "\n",
    "    summary = (\n",
    "        meta[[\"strategy_idx\", \"str_repr\"]]\n",
    "        .assign(wincount=lambda df:\n",
    "                df[\"str_repr\"].map(win_counter).fillna(0).astype(\"int32\"))\n",
    "        .sort_values(\"strategy_idx\")[[\"strategy_idx\", \"wincount\"]]\n",
    "    )\n",
    "    summary.to_csv(\"wincounts.csv\", index=False)\n",
    "    log.info(\"Finished!  CSV written with final results.\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_tournament_v2_debug_fixed.py\n",
    "\"\"\"\n",
    "Run the full Farkle strategy tournament with multiprocessing,\n",
    "queue-based logging, and resumable checkpoints.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import logging.handlers\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import time\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from farkle.simulation import generate_strategy_grid\n",
    "from farkle.stats import games_for_power\n",
    "\n",
    "# Insert a debug statement at top-level after imports\n",
    "log = logging.getLogger(\"tournament\")\n",
    "log.debug(\"reached top-level after imports  vars=%r\", locals())\n",
    "\n",
    "class FirstNFilter(logging.Filter):\n",
    "    \"\"\"\n",
    "    Let every unique call-site (file, lineno) speak `n` times, then silence it.\n",
    "    Works no matter how tight the surrounding loop is.\n",
    "    \"\"\"\n",
    "    def __init__(self, n: int = 10):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.seen: Counter[Tuple[str, int]] = Counter()\n",
    "        log.debug(\"entered FirstNFilter.__init__  vars=%r\", locals())\n",
    "\n",
    "    def filter(self, record: logging.LogRecord) -> bool:\n",
    "        key = (record.pathname, record.lineno)\n",
    "        self.seen[key] += 1\n",
    "        allowed = self.seen[key] <= self.n\n",
    "        log.debug(\"FirstNFilter.filter called  vars=%r\", locals())\n",
    "        return allowed\n",
    "    \n",
    "    \n",
    "DEBUG_FIRST_N = 10    # change once; used by the filter above\n",
    "log.debug(\"set DEBUG_FIRST_N  vars=%r\", locals())\n",
    "\n",
    "root = logging.getLogger()             # grab root so *all* libraries inherit it\n",
    "root.setLevel(logging.DEBUG)           # we really want to see DEBUG\n",
    "log.debug(\"configured root logger  vars=%r\", locals())\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)           # print to notebook cell\n",
    "handler.setFormatter(logging.Formatter(\n",
    "        \"%(asctime)s %(levelname)-5s %(filename)s:%(lineno)d | %(message)s\",\n",
    "        datefmt=\"%H:%M:%S\"))\n",
    "handler.addFilter(FirstNFilter(DEBUG_FIRST_N))        # <── the magic!\n",
    "log.debug(\"configured handler with FirstNFilter  vars=%r\", locals())\n",
    "\n",
    "root.handlers[:] = [handler]            # replace any default Jupyter handlers\n",
    "log.debug(\"replaced root.handlers  vars=%r\", locals())\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 0.--- Globals & tuning knobs\n",
    "CHUNKSIZE       = 10_000          # tasks sent to each worker at a time\n",
    "PROCESSES       = 16\n",
    "MAXTASKS        = 50              # fork a fresh worker after this many tasks\n",
    "REPORT_EVERY    = 100_000         # progress print interval\n",
    "CHECKPOINT_FILE = Path(\"win_counter.chk\")\n",
    "log.debug(\"set globals & tuning knobs  vars=%r\", locals())\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1.--- Strategy grid and powered sample size\n",
    "strategies, meta = generate_strategy_grid()   # 8 160 rows\n",
    "log.debug(\"generated strategy grid  vars=%r\", locals())\n",
    "meta[\"str_repr\"] = [str(s) for s in strategies]\n",
    "log.debug(\"constructed meta['str_repr']  vars=%r\", locals())\n",
    "\n",
    "n_games_per_player = games_for_power(\n",
    "    n_strategies=len(strategies),\n",
    "    delta=0.03, alpha=0.025, power=0.90,\n",
    "    method=\"bh\", pairwise=True,\n",
    ")\n",
    "log.debug(\"computed n_games_per_player  vars=%r\", locals())\n",
    "\n",
    "total_tasks = len(strategies) * n_games_per_player // 5  # == total games\n",
    "log.debug(\"computed total_tasks  vars=%r\", locals())\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format=\"%(asctime)s|%(processName)s|%(levelname)s|%(message)s\",\n",
    "    datefmt=\"%H:%M:%S\")\n",
    "log.debug(\"configured basic logging  vars=%r\", locals())\n",
    "\n",
    "log.info(\"n_games_per_player = %s, total tasks = %s\", n_games_per_player, total_tasks)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.--- Utility: chunk iterable into batches of n\n",
    "def chunker(it, n):\n",
    "    log.debug(\"entered chunker  vars=%r\", locals())\n",
    "    while (batch := list(islice(it, n))):\n",
    "        log.debug(\"chunker yielding batch  vars=%r\", locals())\n",
    "        yield tuple(batch)\n",
    "    log.debug(\"chunker exiting (no more batches)  vars=%r\", locals())\n",
    "\n",
    "# 3.--- Deterministic table generator  (same order every run for reproducibility)\n",
    "def make_tables(strats, repeats, seed=42):\n",
    "    log.debug(\"entered make_tables  vars=%r\", locals())\n",
    "    rng = np.random.default_rng(seed)\n",
    "    log.debug(\"initialized RNG in make_tables  vars=%r\", locals())\n",
    "    for rep in range(repeats):\n",
    "        log.debug(\"make_tables at rep start  vars=%r\", locals())\n",
    "        perm = rng.permutation(len(strats))\n",
    "        log.debug(\"make_tables computed perm  vars=%r\", locals())\n",
    "        yield from chunker(perm, 5)\n",
    "        log.debug(\"make_tables yielded tables for rep  vars=%r\", locals())\n",
    "        if rep < 2:                      # quick preview\n",
    "            log.debug(\"rep=%d first table indices=%s\", rep, perm[:5])\n",
    "    log.debug(\"make_tables exiting  vars=%r\", locals())\n",
    "\n",
    "# 4.--- Worker\n",
    "def _one(task):\n",
    "    log.debug(\"entered _one  vars=%r\", locals())\n",
    "    seed, idxs = task\n",
    "    log.debug(\"unpacked task in _one  vars=%r\", locals())\n",
    "    table = [strategies[i] for i in idxs]\n",
    "    log.debug(\"constructed table in _one  vars=%r\", locals())\n",
    "    row   = _play_game(seed, table, 10_000)\n",
    "    log.debug(\"completed _play_game in _one  vars=%r\", locals())\n",
    "    win   = str(row[f\"{row['winner']}_strategy\"])\n",
    "    log.debug(\"computed win in _one  vars=%r\", locals())\n",
    "    return win\n",
    "\n",
    "# 5.--- Build the (potentially resumable) task stream\n",
    "def task_stream(already_done: int):\n",
    "    \"\"\"\n",
    "    Generator of (seed, indices) tuples.\n",
    "    If *already_done* > 0, the first that many tasks are discarded so that\n",
    "    the stream yields only unfinished work when resuming from a checkpoint.\n",
    "    \"\"\"\n",
    "    log.debug(\"entered task_stream  vars=%r\", locals())\n",
    "    rng         = np.random.default_rng(999)\n",
    "    log.debug(\"initialized RNG in task_stream  vars=%r\", locals())\n",
    "    tables_iter = make_tables(strategies, n_games_per_player)\n",
    "    log.debug(\"created tables_iter in task_stream  vars=%r\", locals())\n",
    "\n",
    "    # fast-forward to resume point\n",
    "    if already_done:\n",
    "        log.debug(\"task_stream skipping already_done tasks  vars=%r\", locals())\n",
    "        skipped = 0\n",
    "        for _ in range(already_done):\n",
    "            next(tables_iter)\n",
    "            skipped += 1\n",
    "            log.debug(\"task_stream skipped one task  vars=%r\", locals())\n",
    "        log.debug(\"task_stream done skipping tasks  vars=%r\", locals())\n",
    "        log.info(\"Skipped %s completed tasks from previous run.\", skipped)\n",
    "\n",
    "    for idxs in tables_iter:\n",
    "        log.debug(\"task_stream about to yield a task  vars=%r\", locals())\n",
    "        yield (rng.integers(0, 2**32 - 1), idxs)\n",
    "    log.debug(\"task_stream exiting (no more tasks)  vars=%r\", locals())\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 6.--- Checkpoint helpers\n",
    "def save_checkpoint(counter: Counter, done: int):\n",
    "    log.debug(\"entered save_checkpoint  vars=%r\", locals())\n",
    "    with CHECKPOINT_FILE.open(\"wb\") as f:\n",
    "        pickle.dump({\"done\": done, \"counter\": dict(counter)}, f)\n",
    "        log.debug(\"pickle.dump completed in save_checkpoint  vars=%r\", locals())\n",
    "    log.info(\"Checkpoint saved at %s tasks.\", done)\n",
    "    log.debug(\"exiting save_checkpoint  vars=%r\", locals())\n",
    "\n",
    "def load_checkpoint() -> tuple[int, Counter]:\n",
    "    log.debug(\"entered load_checkpoint  vars=%r\", locals())\n",
    "    if not CHECKPOINT_FILE.exists():\n",
    "        log.debug(\"load_checkpoint found no checkpoint file  vars=%r\", locals())\n",
    "        return 0, Counter()\n",
    "    with CHECKPOINT_FILE.open(\"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        log.debug(\"pickle.load completed in load_checkpoint  vars=%r\", locals())\n",
    "    log.info(\"Checkpoint loaded: %s tasks finished previously.\", data[\"done\"])\n",
    "    log.debug(\"exiting load_checkpoint with data  vars=%r\", locals())\n",
    "    return data[\"done\"], Counter(data[\"counter\"])\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 7.--- Multiprocessing-friendly logging (single queue sink)\n",
    "def _configure_worker_logging(queue):\n",
    "    log.debug(\"entered _configure_worker_logging  vars=%r\", locals())\n",
    "    qh = logging.handlers.QueueHandler(queue)\n",
    "    root = logging.getLogger()\n",
    "    root.handlers.clear()\n",
    "    root.setLevel(logging.DEBUG)\n",
    "    root.addHandler(qh)\n",
    "    log.debug(\"configured worker logging handlers  vars=%r\", locals())\n",
    "\n",
    "def _listener_process(queue):\n",
    "    log.debug(\"entered _listener_process  vars=%r\", locals())\n",
    "    h = logging.StreamHandler(sys.stdout)\n",
    "    fmt = logging.Formatter(\"%(asctime)s|%(processName)s|%(levelname)s|%(message)s\",\n",
    "                            \"%H:%M:%S\")\n",
    "    h.setFormatter(fmt)\n",
    "    root = logging.getLogger()\n",
    "    root.addHandler(h)\n",
    "    root.setLevel(logging.DEBUG)\n",
    "    log.debug(\"listener configured its handler  vars=%r\", locals())\n",
    "    while True:\n",
    "        record = queue.get()\n",
    "        log.debug(\"listener received record  vars=%r\", locals())\n",
    "        if record is None:\n",
    "            log.debug(\"listener received sentinel None  vars=%r\", locals())\n",
    "            break\n",
    "        root.handle(record)\n",
    "    log.debug(\"listener exiting  vars=%r\", locals())\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    log.debug(\"entered main  vars=%r\", locals())\n",
    "    already_done, win_counter = load_checkpoint()\n",
    "    log.debug(\"after load_checkpoint in main  vars=%r\", locals())\n",
    "    if already_done >= total_tasks:\n",
    "        log.debug(\"main early exit condition met  vars=%r\", locals())\n",
    "        log.warning(\"All %s tasks are already complete. Nothing to do!\", total_tasks)\n",
    "        return\n",
    "\n",
    "    log_queue = mp.Queue()\n",
    "    log.debug(\"created log_queue in main  vars=%r\", locals())\n",
    "    listener  = mp.Process(target=_listener_process, args=(log_queue,), daemon=True)\n",
    "    listener.start()\n",
    "    log.debug(\"started listener process in main  vars=%r\", locals())\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    log.debug(\"recorded start_time in main  vars=%r\", locals())\n",
    "    done = already_done\n",
    "    log.debug(\"initialized done counter in main  vars=%r\", locals())\n",
    "\n",
    "    with mp.Pool(\n",
    "        processes=PROCESSES,\n",
    "        maxtasksperchild=MAXTASKS,\n",
    "        initializer=_configure_worker_logging,\n",
    "        initargs=(log_queue,),\n",
    "    ) as pool:\n",
    "        log.debug(\"entered Pool context in main  vars=%r\", locals())\n",
    "        log.info(\"Pool started with %d workers.\", PROCESSES)\n",
    "        log.debug(\"logged pool start info in main  vars=%r\", locals())\n",
    "        stream = task_stream(already_done)\n",
    "        log.debug(\"created stream iterator in main  vars=%r\", locals())\n",
    "        for win in pool.imap_unordered(_one, stream, chunksize=CHUNKSIZE):\n",
    "            log.debug(\"received win from pool.imap_unordered  vars=%r\", locals())\n",
    "            win_counter[win] += 1\n",
    "            log.debug(\"updated win_counter in main loop  vars=%r\", locals())\n",
    "            done += 1\n",
    "            log.debug(\"incremented done in main loop  vars=%r\", locals())\n",
    "\n",
    "            if done % REPORT_EVERY == 0 or done == total_tasks:\n",
    "                pct = 100 * done / total_tasks\n",
    "                hrs = (time.perf_counter() - start_time) / 3600\n",
    "                log.debug(\"about to log progress in main loop  vars=%r\", locals())\n",
    "                log.info(\"[%10d / %10d]  %6.2f %%  %6.2f h elapsed\",\n",
    "                         done, total_tasks, pct, hrs)\n",
    "                log.debug(\"about to save checkpoint in main loop  vars=%r\", locals())\n",
    "                save_checkpoint(win_counter, done)\n",
    "                log.debug(\"saved checkpoint in main loop  vars=%r\", locals())\n",
    "        log.debug(\"exited for loop in main  vars=%r\", locals())\n",
    "\n",
    "    # tell listener to finish\n",
    "    log.debug(\"sending sentinel to listener  vars=%r\", locals())\n",
    "    log_queue.put(None)\n",
    "    log.debug(\"sent sentinel to listener  vars=%r\", locals())\n",
    "    listener.join()\n",
    "    log.debug(\"listener joined in main  vars=%r\", locals())\n",
    "\n",
    "    # final dump + CSV\n",
    "    log.debug(\"about to save final checkpoint  vars=%r\", locals())\n",
    "    save_checkpoint(win_counter, done)\n",
    "    log.debug(\"saved final checkpoint  vars=%r\", locals())\n",
    "\n",
    "    summary = (\n",
    "        meta[[\"strategy_idx\", \"str_repr\"]]\n",
    "        .assign(wincount=lambda df:\n",
    "                df[\"str_repr\"].map(win_counter).fillna(0).astype(\"int32\"))\n",
    "        .sort_values(\"strategy_idx\")[[\"strategy_idx\", \"wincount\"]]\n",
    "    )\n",
    "    log.debug(\"constructed summary DataFrame  vars=%r\", locals())\n",
    "    summary.to_csv(\"wincounts.csv\", index=False)\n",
    "    log.debug(\"wrote wincounts.csv  vars=%r\", locals())\n",
    "    log.info(\"Finished!  CSV written with final results.\")\n",
    "    log.debug(\"exiting main  vars=%r\", locals())\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    log.debug(\"about to call main from __main__  vars=%r\", locals())\n",
    "    main()\n",
    "    log.debug(\"returned from main in __main__  vars=%r\", locals())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
