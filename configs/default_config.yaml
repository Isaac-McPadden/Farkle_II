# configs/default_config.yaml
# Drives BOTH simulation and analysis.
# This config pins the library defaults for reference use only.

io:
  results_dir: "results"    # Path|str: base results directory
  append_seed: true         # bool: append sim.seed suffix to results_dir
  analysis_subdir: "analysis"    # str: analysis outputs subdirectory under results_dir
  meta_analysis_dir: null   # Path|str|None: optional shared directory for per-seed summaries

sim:
  n_players_list: [5]       # list[int]: table sizes to simulate
  num_shuffles: 100         # int: default shuffle count per table size
  seed: 0                   # int: primary RNG seed + results_dir suffix when append_seed=true
  seed_pair: [0, 1]          # tuple[int,int]|None: two-seed orchestration pair; seed still drives suffixing
  expanded_metrics: false   # bool: write expanded metrics parquet
  row_dir: null             # Path|str|None: relative folder for row dumps; null skips write
  per_n: {}                 # dict[int, SimConfig]: per-table overrides mirroring sim options
  power_method: "bh"        # str: 'bh' or 'bonferroni' for scheduling strategy
  recompute_num_shuffles: true    # bool: derive per-N shuffles from power design
  power_design:
    power: 0.8              # float: target statistical power
    control: 0.1            # float: FDR q (BH) or alpha (Bonferroni)
    detectable_lift: 0.03   # float: minimum absolute lift to detect
    baseline_rate: 0.5      # float: assumed baseline win rate
    tail: "two_sided"       # str: 'one_sided' or 'two_sided'
    full_pairwise: true     # bool: compare all pairs vs top-1
    endpoint: "pairwise"    # str: 'pairwise' or 'top1'
    min_games_floor: 2000   # int: minimum scheduled games
    max_games_cap: null     # int|None: optional cap on games
    use_BY: false           # bool: enable Benjamini-Yekutieli correction for BH
    bh_target_rank: null    # int|None: target BH order statistic i*
    bh_target_frac: 0.03    # float|None: target discovery fraction for BH
  n_jobs: null              # int|None: parallel workers for simulation
  desired_sec_per_chunk: 10 # int: target seconds per work chunk
  ckpt_every_sec: 30        # int: checkpoint interval in seconds
  score_thresholds: null    # list[int]|None: custom threshold grid for scoring
  dice_thresholds: null     # list[int]|None: custom dice thresholds
  smart_five_opts: null     # sequence[bool]|None: toggle smart five behavior
  smart_one_opts: null      # sequence[bool]|None: toggle smart one behavior
  consider_score_opts: [true, false]   # sequence[bool]: include score-based branching
  consider_dice_opts: [true, false]    # sequence[bool]: include dice-count branching
  auto_hot_dice_opts: [true, false]    # sequence[bool]: auto roll on hot dice
  run_up_score_opts: [true, false]     # sequence[bool]: allow run-up scoring strategy
  include_stop_at: false               # bool: append stop_at_{350,400,450,500} variants
  include_stop_at_heuristic: false     # bool: append heuristic stop-at variants

analysis:
  run_trueskill: true       # bool: compute TrueSkill ratings
  run_interseed: true       # bool: include cross-seed analytics stages (variance/meta/pooled)
  run_head2head: true       # bool: execute head-to-head analysis
  run_rng: false            # bool: run RNG diagnostics over curated rows
  run_game_stats: true      # bool: compute pooled game statistics after metrics
  run_hgb: true             # bool: train histogram gradient boosting model
  run_frequentist: false    # bool: plan step 6 frequentist/MDD tiering + tiering_report
  run_post_h2h_analysis: false  # bool: post head-to-head cleanup (plan step 5)
  run_agreement: false      # bool: agreement heuristics (plan step 8)
  run_report: true          # bool: report writer / publishing (plan step 9)
  n_jobs: 1                 # int: parallel workers for analysis
  log_level: "INFO"         # str: logger level during analysis
  results_glob: "*_players" # str: glob selecting per-N result folders
  head2head_target_hours: 8.0         # float: target runtime window for Bonferroni H2H (<=0 disables)
  head2head_tolerance_pct: 5.0        # float: acceptable +/- percent around target hours
  head2head_games_per_sec: null       # float|None: measured H2H throughput (games per second)
  tiering_seeds: null       # list[int]|None: seeds to include in tiering report (default current seed)
  tiering_z_star: 1.645     # float: z* threshold for MDD tiers
  tiering_min_gap: null     # float|None: minimum gap required to split tiers
  tiering_weights_by_k: null  # dict[int,float]|None: optional weights for player counts
  meta_max_other_seeds: null # int|None: cap on non-primary seeds used in meta pooling
  meta_comparison_seed: null # int|None: fixed comparison seed when limiting meta pooling
  outputs: {}               # dict[str, Any]: optional custom output filenames

ingest:
  row_group_size: 64000     # int: parquet row-group size
  parquet_codec: "snappy"   # str: parquet compression codec
  batch_rows: 100000        # int: rows processed per batch
  n_jobs: 1                 # int: concurrent ingest workers

combine:
  max_players: 12           # int: maximum table size to combine

metrics:
  seat_range: [1, 12]       # list[int]|tuple[int,int]: seats included in metrics

trueskill:
  beta: 25.0                # float: performance variability parameter
  tau: 0.1                  # float: dynamics factor between runs
  draw_probability: 0.0     # float: draw probability
  pooled_weights_by_k:      # dict[int, float]|None: optional weights per player count for pooling

head2head:
  n_jobs: 4                 # int: parallel workers for head-to-head stage
  games_per_pair: 10000     # int: baseline games scheduled per pair
  fdr_q: 0.02               # float: FDR control threshold for BH
  bonferroni_design: {}     # dict[str, Any]: optional Bonferroni scheduling overrides

hgb:
  max_depth: 6              # int: maximum tree depth
  n_estimators: 300         # int: boosting iterations
